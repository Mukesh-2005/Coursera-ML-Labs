# ğŸ§ª Dimensionality Reduction Lab: t-SNE vs UMAP vs PCA

## ğŸ¯ Objective
To compare three popular dimensionality reduction techniques â€” **t-SNE**, **UMAP**, and **PCA** â€” on a synthetic 3D dataset. The goal is to evaluate how well each method preserves cluster structure in terms of separation, density, and relative distances.

---

## ğŸ“ Dataset
- **Type**: Synthetic 3D blobs
- **Samples**: 500
- **Clusters**: 4
- **Centers**: [[2, -6, -6], [-1, 9, 4], [-8, 7, 2], [4, 7, 9]]
- **Standard deviations**: `[1, 1, 2, 3.5]`

---

## ğŸ§° Tools & Libraries
- `numpy`, `pandas`, `matplotlib`, `plotly`
- `sklearn`: `make_blobs`, `StandardScaler`, `TSNE`, `PCA`
- `umap`: `UMAP`

---

## ğŸ”„ Workflow Summary

### 1. Data Generation
- Created synthetic blobs with varied spread.
- Stored true labels for evaluation.

### 2. 3D Visualization
- Used `plotly.express.scatter_3d` for interactive inspection of cluster density and overlap.

### 3. Standardization
- Applied `StandardScaler()` to normalize features before projection.

### 4. Dimensionality Reduction

| Method | Parameters | Key Observations |
|--------|------------|------------------|
| **t-SNE** | `perplexity=30`, `max_iter=1000` | Strong cluster separation, good local structure, some global distortion. |
| **UMAP** | `min_dist=0.5`, `spread=1` | Balanced local/global structure, preserved continuity between overlapping clusters. |
| **PCA** | `n_components=2` | Fastest; preserved variance and relative distances well despite being linear. |

---

## ğŸ“Š Outputs

- âœ… Interactive 3D plot of original blobs
- âœ… 2D scatter plots for:
- t-SNE projection
- UMAP projection
- PCA projection
- âœ… Text cells with observations and interpretation prompts

---

## ğŸ§  Comparative Summary

| Method | Strengths | Weaknesses |
|--------|-----------|------------|
| **t-SNE** | Excellent local clustering; visually distinct clusters | Global distances may be misleading; sensitive to hyperparameters |
| **UMAP** | Balances local/global structure; preserves continuity | Sensitive to `n_neighbors`, `min_dist`; results can vary |
| **PCA** | Fast, interpretable, preserves variance | Canâ€™t capture non-linear structure |

ğŸ“Œ In this experiment:
- **PCA** was surprisingly effective and fast.
- **t-SNE** gave strong separation.
- **UMAP** offered a more connected, interpretable view of overlapping clusters.

---

## ğŸ”¬ Suggested Next Steps

- âœ… Run all cells to capture final plots and numerical outputs.
- ğŸ”§ Tune hyperparameters:
- t-SNE: Try `perplexity` from 5 to 50, adjust `early_exaggeration`.
- UMAP: Experiment with `n_neighbors`, `min_dist`, `spread`.
- ğŸ“ˆ Quantify embeddings:
- Use **Silhouette Score**, **Adjusted Rand Index**, or **Trustworthiness**.
- ğŸ’¾ Save visuals and scripts:
- Export best plots and document findings.
- Create a reproducible script with tuned parameters.

---

## ğŸ—£ï¸ Reflections
This lab helped me understand how different dimensionality reduction techniques behave on clustered data. I learned how to interpret 2D projections, tune hyperparameters, and evaluate embeddings both visually and quantitatively.

---
>Built by Mukesh â€” part of my unsupervised learning series
>ğŸ“… Last updated: November 2025
